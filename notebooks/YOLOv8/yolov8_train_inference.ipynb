{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8l.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(\n",
    "#     data=\"/mnt/c/Users/Rahul/Desktop/datasets/License with annotations/data.yaml\",\n",
    "#     epochs=100,\n",
    "#     patience=4,              \n",
    "#     batch=12,               \n",
    "#     imgsz=600,              \n",
    "#     device=0,               \n",
    "#     name=\"Medium model with patience 4, img 600, SGD,  dropout 0.3 , batch 12\",         \n",
    "#     optimizer=\"SGD\",        \n",
    "#     verbose=True,            \n",
    "#     seed=42,                 \n",
    "#     weight_decay=0.0005,      \n",
    "#     dropout=0.3,           \n",
    "#     val=True,  \n",
    "#     plots=True, \n",
    "# )\n",
    "\n",
    "#code to find the best hyperparameters\n",
    "model.tune(data=\"../data.yaml\", epochs=30, iterations=300, optimizer=\"AdamW\", plots=True, save=True, val=True)\n",
    "\n",
    "\n",
    "model.train(\n",
    "    data=\"../data.yaml\",  # Path to the dataset configuration file\n",
    "    epochs=100,  # Number of training epochs\n",
    "    patience=4,  # Number of epochs with no improvement in validation loss before stopping\n",
    "    batch=12,  # Batch size for training\n",
    "    imgsz=600,  # Image size for training\n",
    "    device=0,  # Device ID (0 for the first GPU)\n",
    "    name=\"Citizenship model with epochs 100, patience 4, batch size 12 , dropout 0.4\",  # Name for the model folder\n",
    "    optimizer=\"AdamW\",  # Optimizer to use (Stochastic Gradient Descent)\n",
    "    verbose=True,  # Print detailed logs during training\n",
    "    weight_decay=0.001,  # Weight decay for regularization\n",
    "    dropout=0.4,  # Dropout rate to prevent overfitting\n",
    "    val=True,  # Enable validation during training\n",
    "    plots=True,  # Generate plots for training metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single image inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/mnt/c/Users/Rahul/Desktop/Document-and-Record-Management/notebooks/YOLOv8/runs/detect/Citizenship with large model with patience 6, img 600, SGD,  dropout 0.4 , batch 12/weights/best.pt\")\n",
    "model.predict(source=\"/mnt/c/Users/Rahul/Desktop/Document-and-Record-Management/notebooks/YOLOv8/a.jpg\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folder inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/mnt/c/Users/Rahul/Desktop/trained models/Citizenship_model.pt\")\n",
    "folder_path = \"/mnt/c/Users/Rahul/Desktop/Test/Citizenship\"\n",
    "\n",
    "for image_name in os.listdir(folder_path):\n",
    "    if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        model.predict(source=image_path, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.98 ðŸš€ Python-3.10.15 torch-2.4.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 268 layers, 43,610,463 parameters, 0 gradients, 164.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/Rahul/Desktop/YOLO evaluation/Citizenship/labels/val.cache... 91 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         91        420      0.949      0.941       0.97      0.577\n",
      "    citizenship_number         90         91      0.944      0.901      0.953      0.544\n",
      "              district         86         86      0.931      0.965      0.978      0.622\n",
      "                gender         91         94      0.956      0.968      0.974      0.556\n",
      "                  name         91         91      0.971          1      0.995      0.555\n",
      "                  year         58         58      0.944      0.872      0.951       0.61\n",
      "Speed: 1.2ms preprocess, 20.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving runs/detect/val7/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val7\u001b[0m\n",
      "Available metrics for Citizenship: dict_keys(['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'fitness'])\n",
      "Metrics for Citizenship not found, skipping.\n",
      "Ultralytics YOLOv8.2.98 ðŸš€ Python-3.10.15 torch-2.4.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 268 layers, 43,610,463 parameters, 0 gradients, 164.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/Rahul/Desktop/YOLO evaluation/License/labels/val... 132 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:00<00:00, 229.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Users/Rahul/Desktop/YOLO evaluation/License/labels/val.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 50, len(boxes) = 664. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        132        664      0.809       0.93      0.913      0.533\n",
      "    citizenship_number        132        133      0.798      0.923      0.892      0.506\n",
      "        contact_number        132        133      0.615      0.917      0.892      0.546\n",
      "                   dob        132        133      0.773       0.91      0.888      0.551\n",
      "        license_number        132        133      0.905      0.947      0.949      0.573\n",
      "                  name        132        132      0.955      0.954      0.945      0.488\n",
      "Speed: 1.1ms preprocess, 19.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Saving runs/detect/val8/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val8\u001b[0m\n",
      "Available metrics for License: dict_keys(['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'fitness'])\n",
      "Metrics for License not found, skipping.\n",
      "Ultralytics YOLOv8.2.98 ðŸš€ Python-3.10.15 torch-2.4.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 218 layers, 25,842,655 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/Rahul/Desktop/YOLO evaluation/Passport/labels/val... 97 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97/97 [00:00<00:00, 245.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Users/Rahul/Desktop/YOLO evaluation/Passport/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         97        337      0.978      0.983      0.989      0.743\n",
      "    citizenship_number         45         45      0.994      0.978      0.979      0.738\n",
      "                   dob         54         55      0.982      0.977      0.986      0.778\n",
      "                  name         95         95      0.982      0.989      0.994      0.772\n",
      "       passport_number         47         47      0.938      0.979      0.989      0.669\n",
      "               surname         95         95      0.992      0.989      0.995       0.76\n",
      "Speed: 3.0ms preprocess, 16.6ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
      "Saving runs/detect/val9/predictions.json...\n",
      "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n",
      "Available metrics for Passport: dict_keys(['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'fitness'])\n",
      "Metrics for Passport not found, skipping.\n",
      "Evaluation complete. Results saved in the 'results' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define paths for each document category\n",
    "document_categories = ['Citizenship', 'License', 'Passport']\n",
    "results_dir = '/mnt/c/Users/Rahul/Desktop/YOLO evaluation/results/'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each document category\n",
    "for category in document_categories:\n",
    "    model_path = f\"/mnt/c/Users/Rahul/Desktop/trained models/{category}_model.pt\"\n",
    "    folder_path = f\"/mnt/c/Users/Rahul/Desktop/YOLO evaluation/{category}/\"\n",
    "    \n",
    "    # Load the model\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Evaluate the model on the dataset\n",
    "    metrics = model.val(data=os.path.join(folder_path, 'data.yaml'), save_json=True, save_conf=True)\n",
    "\n",
    "    # Extract metrics using the results_dict method\n",
    "    results = metrics.results_dict\n",
    "\n",
    "    # Print available keys for debugging\n",
    "    print(f\"Available metrics for {category}: {results.keys()}\")\n",
    "\n",
    "    # Extract metrics safely\n",
    "    mAP = results.get('mAP', {}).get(0, None)  # mAP at IoU=0.5\n",
    "    precision = results.get('precision', None)  # Precision\n",
    "    recall = results.get('recall', None)  # Recall\n",
    "\n",
    "    if mAP is None or precision is None or recall is None:\n",
    "        print(f\"Metrics for {category} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Save results to a text file\n",
    "    with open(os.path.join(results_dir, f\"{category}_evaluation_results.txt\"), 'w') as f:\n",
    "        f.write(f\"Mean Average Precision (mAP): {mAP:.4f}\\n\")\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "\n",
    "    # Save predictions and metrics\n",
    "    model.predict(source=os.path.join(folder_path, 'images/val'), save=True)\n",
    "\n",
    "print(\"Evaluation complete. Results saved in the 'results' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnnlocalizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
